{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "MODEL_PATH = 'models/'\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The data has been organized into train and validation foldes with each car make in its separate subfolder.\n",
    "\n",
    "The training data has been augmented beforehand with 90 degree rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = image.ImageDataGenerator(\n",
    "    rotation_range=5, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale = 1/255.,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15655 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_generator.flow_from_directory(\n",
    "    DATA_PATH + 'train/',\n",
    "    target_size=(299, 299),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_generator = image.ImageDataGenerator(\n",
    "    rescale = 1/255.,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1967 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_batches = valid_generator.flow_from_directory(\n",
    "    DATA_PATH + 'valid/',\n",
    "    target_size=(299, 299),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = train_batches.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Build model\n",
    " \n",
    " Using Xception V1 model as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, train_batches):\n",
    "    now = datetime.now()\n",
    "    \n",
    "    model_name = MODEL_PATH + f'carnet-{now.date().isoformat()}_{now.hour*60 + now.minute}'\n",
    "\n",
    "    model.save_weights(model_name + '-weights.h5')\n",
    "    with open(model_name + '-model.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    \n",
    "    with open(model_name + '-classes.json', 'w') as f:\n",
    "        json.dump(train_batches.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    with open(MODEL_PATH + model_name + '-model.json') as f:\n",
    "        model = model_from_json(f.read())\n",
    "        \n",
    "    model.load_weights(MODEL_PATH + model_name + '-weights.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave only the last two added layers trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 1 512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 2 32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 2 1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 7 186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 7 2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           20490       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 20,881,970\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "123/123 [==============================] - 584s 5s/step - loss: 2.0357 - acc: 0.2865 - val_loss: 2.2427 - val_acc: 0.1871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe32852e048>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_batches,\n",
    "    steps_per_epoch=int(ceil(train_batches.samples/BATCH_SIZE)),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=int(ceil(valid_batches.samples/BATCH_SIZE)),\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 583s 5s/step - loss: 1.8579 - acc: 0.3676 - val_loss: 1.9906 - val_acc: 0.2933\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.7753 - acc: 0.3965 - val_loss: 1.8570 - val_acc: 0.3371\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 533s 4s/step - loss: 1.7297 - acc: 0.4082 - val_loss: 1.7408 - val_acc: 0.4128\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.6909 - acc: 0.4224 - val_loss: 1.6883 - val_acc: 0.4199\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.6715 - acc: 0.4322 - val_loss: 1.6954 - val_acc: 0.4052\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 543s 4s/step - loss: 1.6455 - acc: 0.4420 - val_loss: 1.6534 - val_acc: 0.4342\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.6156 - acc: 0.4518 - val_loss: 1.6428 - val_acc: 0.4296\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.6145 - acc: 0.4497 - val_loss: 1.6454 - val_acc: 0.4352\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 545s 4s/step - loss: 1.5976 - acc: 0.4569 - val_loss: 1.6412 - val_acc: 0.4479\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.5824 - acc: 0.4619 - val_loss: 1.6083 - val_acc: 0.4484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe30dbb9320>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_batches,\n",
    "    steps_per_epoch=int(ceil(train_batches.samples/BATCH_SIZE)),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=int(ceil(valid_batches.samples/BATCH_SIZE)),\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 591s 5s/step - loss: 1.5804 - acc: 0.4623 - val_loss: 1.6378 - val_acc: 0.4260\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.5645 - acc: 0.4690 - val_loss: 1.6242 - val_acc: 0.4408\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 542s 4s/step - loss: 1.5536 - acc: 0.4717 - val_loss: 1.5970 - val_acc: 0.4545\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.5396 - acc: 0.4781 - val_loss: 1.6113 - val_acc: 0.4423\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.5279 - acc: 0.4823 - val_loss: 1.5943 - val_acc: 0.4479\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 541s 4s/step - loss: 1.5321 - acc: 0.4814 - val_loss: 1.5846 - val_acc: 0.4606\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 531s 4s/step - loss: 1.5124 - acc: 0.4884 - val_loss: 1.5852 - val_acc: 0.4637\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.5136 - acc: 0.4891 - val_loss: 1.5894 - val_acc: 0.4413\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.4955 - acc: 0.4962 - val_loss: 1.5900 - val_acc: 0.4459\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 541s 4s/step - loss: 1.4967 - acc: 0.4925 - val_loss: 1.5711 - val_acc: 0.4550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe30dbb95f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_batches,\n",
    "    steps_per_epoch=int(ceil(train_batches.samples/BATCH_SIZE)),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=int(ceil(valid_batches.samples/BATCH_SIZE)),\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 581s 5s/step - loss: 1.4823 - acc: 0.5039 - val_loss: 1.5781 - val_acc: 0.4514\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.4861 - acc: 0.4978 - val_loss: 1.5419 - val_acc: 0.4814\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 533s 4s/step - loss: 1.4855 - acc: 0.4976 - val_loss: 1.5750 - val_acc: 0.4540\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 543s 4s/step - loss: 1.4789 - acc: 0.5006 - val_loss: 1.5669 - val_acc: 0.4677\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 533s 4s/step - loss: 1.4663 - acc: 0.5043 - val_loss: 1.5279 - val_acc: 0.4748\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.4591 - acc: 0.5075 - val_loss: 1.5897 - val_acc: 0.4514\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.4574 - acc: 0.5087 - val_loss: 1.5900 - val_acc: 0.4565\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.4599 - acc: 0.5079 - val_loss: 1.5300 - val_acc: 0.4667\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.4517 - acc: 0.5093 - val_loss: 1.5298 - val_acc: 0.4865\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 544s 4s/step - loss: 1.4568 - acc: 0.5082 - val_loss: 1.5741 - val_acc: 0.4504\n",
      "2:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 578s 5s/step - loss: 1.4437 - acc: 0.5134 - val_loss: 1.5431 - val_acc: 0.4647\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 542s 4s/step - loss: 1.4488 - acc: 0.5041 - val_loss: 1.5176 - val_acc: 0.4835\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 542s 4s/step - loss: 1.4333 - acc: 0.5214 - val_loss: 1.5430 - val_acc: 0.4759\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.4257 - acc: 0.5197 - val_loss: 1.5317 - val_acc: 0.4698\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 530s 4s/step - loss: 1.4357 - acc: 0.5138 - val_loss: 1.5212 - val_acc: 0.4794\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.4315 - acc: 0.5139 - val_loss: 1.5498 - val_acc: 0.4738\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 545s 4s/step - loss: 1.4218 - acc: 0.5190 - val_loss: 1.5486 - val_acc: 0.4708\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.4250 - acc: 0.5179 - val_loss: 1.5158 - val_acc: 0.4759\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.4235 - acc: 0.5227 - val_loss: 1.5146 - val_acc: 0.4748\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.4164 - acc: 0.5182 - val_loss: 1.5249 - val_acc: 0.4860\n",
      "3:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 582s 5s/step - loss: 1.4106 - acc: 0.5262 - val_loss: 1.5191 - val_acc: 0.4850\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.4110 - acc: 0.5260 - val_loss: 1.5271 - val_acc: 0.4738\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.4073 - acc: 0.5277 - val_loss: 1.5084 - val_acc: 0.4840\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.4164 - acc: 0.5238 - val_loss: 1.5339 - val_acc: 0.4718\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.3985 - acc: 0.5316 - val_loss: 1.5196 - val_acc: 0.4779\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.4016 - acc: 0.5229 - val_loss: 1.4974 - val_acc: 0.4942\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3973 - acc: 0.5279 - val_loss: 1.5259 - val_acc: 0.4738\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.3980 - acc: 0.5253 - val_loss: 1.5141 - val_acc: 0.4616\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3902 - acc: 0.5312 - val_loss: 1.5254 - val_acc: 0.4723\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 543s 4s/step - loss: 1.3946 - acc: 0.5287 - val_loss: 1.5002 - val_acc: 0.4814\n",
      "4:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 581s 5s/step - loss: 1.3859 - acc: 0.5324 - val_loss: 1.5103 - val_acc: 0.4759\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.3914 - acc: 0.5309 - val_loss: 1.5104 - val_acc: 0.4845\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.3794 - acc: 0.5348 - val_loss: 1.5122 - val_acc: 0.4916\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.3889 - acc: 0.5301 - val_loss: 1.5096 - val_acc: 0.4845\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 542s 4s/step - loss: 1.3801 - acc: 0.5307 - val_loss: 1.5318 - val_acc: 0.4799\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3710 - acc: 0.5397 - val_loss: 1.4892 - val_acc: 0.4850\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3763 - acc: 0.5332 - val_loss: 1.5110 - val_acc: 0.4896\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.3836 - acc: 0.5361 - val_loss: 1.5098 - val_acc: 0.4804\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.3786 - acc: 0.5360 - val_loss: 1.4953 - val_acc: 0.4896\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3695 - acc: 0.5383 - val_loss: 1.5138 - val_acc: 0.4799\n",
      "5:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 588s 5s/step - loss: 1.3714 - acc: 0.5361 - val_loss: 1.5018 - val_acc: 0.4977\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 533s 4s/step - loss: 1.3628 - acc: 0.5372 - val_loss: 1.5187 - val_acc: 0.4698\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3671 - acc: 0.5385 - val_loss: 1.4767 - val_acc: 0.4936\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3631 - acc: 0.5382 - val_loss: 1.4921 - val_acc: 0.4901\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.3595 - acc: 0.5450 - val_loss: 1.4999 - val_acc: 0.4835\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 541s 4s/step - loss: 1.3716 - acc: 0.5368 - val_loss: 1.4994 - val_acc: 0.4952\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.3531 - acc: 0.5430 - val_loss: 1.5035 - val_acc: 0.4820\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3590 - acc: 0.5419 - val_loss: 1.4838 - val_acc: 0.4779\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3608 - acc: 0.5418 - val_loss: 1.5060 - val_acc: 0.4957\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.3702 - acc: 0.5358 - val_loss: 1.5083 - val_acc: 0.4840\n",
      "6:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 585s 5s/step - loss: 1.3448 - acc: 0.5507 - val_loss: 1.5128 - val_acc: 0.4743\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.3577 - acc: 0.5421 - val_loss: 1.4873 - val_acc: 0.4855\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.3445 - acc: 0.5443 - val_loss: 1.4841 - val_acc: 0.4916\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 533s 4s/step - loss: 1.3421 - acc: 0.5492 - val_loss: 1.5301 - val_acc: 0.4774\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 531s 4s/step - loss: 1.3545 - acc: 0.5446 - val_loss: 1.4694 - val_acc: 0.4936\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 542s 4s/step - loss: 1.3552 - acc: 0.5410 - val_loss: 1.4894 - val_acc: 0.4891\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3399 - acc: 0.5481 - val_loss: 1.4954 - val_acc: 0.5003\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3454 - acc: 0.5466 - val_loss: 1.4997 - val_acc: 0.4804\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 546s 4s/step - loss: 1.3436 - acc: 0.5508 - val_loss: 1.4782 - val_acc: 0.4875\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.3372 - acc: 0.5483 - val_loss: 1.4908 - val_acc: 0.4850\n",
      "7:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 586s 5s/step - loss: 1.3325 - acc: 0.5496 - val_loss: 1.5152 - val_acc: 0.4677\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 540s 4s/step - loss: 1.3402 - acc: 0.5475 - val_loss: 1.4850 - val_acc: 0.4875\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.3404 - acc: 0.5468 - val_loss: 1.4979 - val_acc: 0.4881\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 544s 4s/step - loss: 1.3385 - acc: 0.5497 - val_loss: 1.4878 - val_acc: 0.4921\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.3434 - acc: 0.5435 - val_loss: 1.4884 - val_acc: 0.4855\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 543s 4s/step - loss: 1.3349 - acc: 0.5488 - val_loss: 1.4881 - val_acc: 0.4931\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.3334 - acc: 0.5482 - val_loss: 1.4895 - val_acc: 0.4972\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.3315 - acc: 0.5499 - val_loss: 1.4719 - val_acc: 0.4982\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.3276 - acc: 0.5535 - val_loss: 1.4972 - val_acc: 0.4931\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3222 - acc: 0.5558 - val_loss: 1.4880 - val_acc: 0.4814\n",
      "8:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 580s 5s/step - loss: 1.3278 - acc: 0.5514 - val_loss: 1.4744 - val_acc: 0.4977\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3305 - acc: 0.5499 - val_loss: 1.5006 - val_acc: 0.4875\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.3185 - acc: 0.5552 - val_loss: 1.4792 - val_acc: 0.4865\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 541s 4s/step - loss: 1.3305 - acc: 0.5484 - val_loss: 1.5081 - val_acc: 0.4774\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 538s 4s/step - loss: 1.3270 - acc: 0.5535 - val_loss: 1.4632 - val_acc: 0.4906\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.3287 - acc: 0.5513 - val_loss: 1.4630 - val_acc: 0.4947\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3060 - acc: 0.5599 - val_loss: 1.5374 - val_acc: 0.4733\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.3209 - acc: 0.5564 - val_loss: 1.4657 - val_acc: 0.4967\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3141 - acc: 0.5529 - val_loss: 1.4648 - val_acc: 0.4962\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.3180 - acc: 0.5520 - val_loss: 1.4931 - val_acc: 0.4794\n",
      "9:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 579s 5s/step - loss: 1.3200 - acc: 0.5531 - val_loss: 1.4651 - val_acc: 0.4947\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3273 - acc: 0.5533 - val_loss: 1.4775 - val_acc: 0.4957\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 533s 4s/step - loss: 1.3172 - acc: 0.5602 - val_loss: 1.4956 - val_acc: 0.4769\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 545s 4s/step - loss: 1.3118 - acc: 0.5572 - val_loss: 1.4916 - val_acc: 0.4860\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3131 - acc: 0.5591 - val_loss: 1.4791 - val_acc: 0.4784\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.3109 - acc: 0.5556 - val_loss: 1.4764 - val_acc: 0.5018\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3088 - acc: 0.5577 - val_loss: 1.5009 - val_acc: 0.4799\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 541s 4s/step - loss: 1.3203 - acc: 0.5581 - val_loss: 1.4602 - val_acc: 0.4926\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 534s 4s/step - loss: 1.3146 - acc: 0.5536 - val_loss: 1.4723 - val_acc: 0.5023\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 536s 4s/step - loss: 1.3092 - acc: 0.5583 - val_loss: 1.5093 - val_acc: 0.4794\n",
      "10:\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 582s 5s/step - loss: 1.3094 - acc: 0.5587 - val_loss: 1.5231 - val_acc: 0.4672\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3104 - acc: 0.5557 - val_loss: 1.4360 - val_acc: 0.5114\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3074 - acc: 0.5567 - val_loss: 1.4924 - val_acc: 0.4845\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 539s 4s/step - loss: 1.3080 - acc: 0.5584 - val_loss: 1.4918 - val_acc: 0.4916\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 533s 4s/step - loss: 1.3142 - acc: 0.5519 - val_loss: 1.4690 - val_acc: 0.4967\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 532s 4s/step - loss: 1.3030 - acc: 0.5607 - val_loss: 1.4717 - val_acc: 0.4840\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 540s 4s/step - loss: 1.3042 - acc: 0.5586 - val_loss: 1.5175 - val_acc: 0.4723\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.3122 - acc: 0.5600 - val_loss: 1.4578 - val_acc: 0.5028\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 535s 4s/step - loss: 1.3057 - acc: 0.5580 - val_loss: 1.4925 - val_acc: 0.4764\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 537s 4s/step - loss: 1.3019 - acc: 0.5562 - val_loss: 1.5094 - val_acc: 0.4759\n",
      "11:\n",
      "Epoch 1/10\n",
      " 40/123 [========>.....................] - ETA: 5:46 - loss: 1.2806 - acc: 0.5709"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f'{i+1}:')\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_batches,\n",
    "        steps_per_epoch=int(ceil(train_batches.samples/BATCH_SIZE)),\n",
    "        validation_data=valid_batches,\n",
    "        validation_steps=int(ceil(valid_batches.samples/BATCH_SIZE)),\n",
    "        epochs=10,\n",
    "    )\n",
    "    \n",
    "    save_model(model, train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
